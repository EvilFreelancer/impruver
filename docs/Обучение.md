# Обучение

Проект `impruver` поддерживает обучение моделей на одной или распределённое на нескольких видеокартах,
по идее можно и на нескольких серверах выполнить обучение, но за неимением оных мне подобное протестировать
пока что не удалось.

## Обучение на одной видеокарте

Прежде чем приступить к обучению модели необходимо подготовить и дедуплицировать датасет, после чего разделить
его на тренировочный и валидационный наборы сэмплов.

Все эти задачи можно выполнить запустив рецепт `compose_dataset` и указав необходимую конфигурацию:

```shell
impruver run compose_dataset --config ./ruGPT-3.5_13B_lora_saiga2.yaml
```

Или используя конфигурацию, идущую в стандартной поставке:

```shell
impruver run compose_dataset --config ruGPT-3.5/13B_lora_saiga2
```

Далее запускаем рецепт `finetune` для обучения трансфорфмерной модели:

```shell
impruver run finetune --config ./ruGPT-3.5_13B_lora_saiga2.yaml
```

Скрипт тренировки поддерживает режим отправки логов в Weights and Biases, но по умолчанию данный функционал отключен,
для того чтобы включить данный функционал нужно добавить опцию `--report-to=wandb` в команду запуска обучения.

По завершению обучения при помощи рецепта `chat` можно запустить интерактивный чат:

```shell
impruver run chat ./ruGPT-3.5_13B_lora_saiga2.yaml
```

## Распределённое обучение (D)DP - (Distributed) Data Parallel

Если у вас на сервере несколько видеокарт, то потребуется выполнить ряд дополнительных настроек.

Для начала необходимо настроить `accelerate` пройдя небольшой опрос выполнив команду:

```shell
accelerate config
```

Пример вопросов и ответов для сервера с тремя видеокартами RTX 4070 Ti.

```
In which compute environment are you running? This machine
Which type of machine are you using? Multi-GPU
How many different machines will you use (in total with all the processes)? 1
Do you wish to use DeepSpeed? No
How many processes in total will you use? 3
Do you wish to use FP16 or BF16 (mixed precision)? bf16
Would you like to enable numa efficiency? (Currently only supported on NVIDIA hardware). Yes
```

Остальное по умолчанию, просто прожимайте Enter пока не закончится.

Далее в YAML-конфигурацию потребуется добавить стройки вида:

```yaml
ddp:
  ddp_find_unused_parameters: false
```

После этого можно будет запустить обучение:

```shell
accelerate launch impruver run finetune --config ./ruGPT-3.5_13B_lora_saiga2.yaml
```

Опция `--report-to=wandb` в таком формате тоже поддерживается.

Далее смотрите в `nvidia-smi` или `nvitop`, модель должна будет запуститься и разлиться на все видеокарты.

При возникновении ошибки: `ValueError: You can’t train a model that has been loaded in 8-bit precision on multiple
devices.` потребуется из пакета `accelerate` импортировать класс `PartialState` и передать его на вход `device_map`
модели.

```shell
from accelerate import PartialState
device_map={"": PartialState().process_index}
```

Подробности [тут](https://medium.com/@sridevi17j/resolving-valueerror-you-cant-train-a-model-that-has-been-loaded-in-8-bit-precision-on-multiple-478d15fdaf8d).
