# Описание секций конфигурации

## Пути

```yml
# Путь к директории в который тренер будет складывать обученную модель и промежуточные результаты
output_dir: ./models/rugpt3small_full

# Путь к JSONL-файлу с подготовленным датасетом обучения
train_path: ./train.rugpt3small.jsonl

# Путь к JSONL-файлу с подготовленным датасетом валидации
val_path: ./val.rugpt3small.jsonl
```

В примере выше мы указываем, что обученная модель и чекпоинты будут сохранены в директории `./models/rugpt3small_full`,
тренировочный датасет будет называться `train.rugpt3small.jsonl` и будет сохранён на уровень выше чекопоинтов модели,
аналогично с валидационным датасетом, только имя будет `val.rugpt3small.jsonl`.

## Секция `datasets`

В данной секции перечислен список датасетов которые должны быть использованы в процессе обучения, при этом
предполагается, что все используемые датасеты загружены на HuggingFace.

Допустим мы планируем обучить модель на комбинации из датасета инструкций и диалогов.

```yaml
datasets:
    # Датасет с инструкциями, применяем конвертер `instruction_to_messages` 
  - name: IlyaGusev/ru_turbo_alpaca
    converter: impruver.instruction_to_messages

    # Датасет с function call примерами, из него нам надо взять первые 1000 элементов сплита train
  - name: korotkov/glaive-function-calling-v2-ru-parsed
    split: train[:1000]

    # Датасет с чатами, применяем `dialog_to_messages` и фильтруем все чаты, количество токенов в которых меньше 1024 токенов
  - name: IlyaGusev/oasst1_ru_main_branch
    converter: impruver.dialog_to_messages
    max_tokens_count: 1024
```

### Параметр `converter`

Отвечает за то какую функцию конвертации элементов датасета потребуется использовать, для того
чтобы преобразовать сэмплы из датасета в формат пригодный для обучения модели.

Если конвертен не указано, то предполагается, что датасет уже имеет правильный формат и в колонке messages содержатся
массивы вида:

```json lines
[{"role": "system", "content": "system text"}, {"role": "user", "content": "user text"}, {"role": "assistant", "content": "assistant text"}]
```

При желании вы можете описать свои функции конвертации и указать в конфигурации к ним путь относительно скрипта для
комбинирования датасета, или же например функции из других пакетов сигнатурах которых совместима с `impruver`.

Подробнее о конвертерах [тут](./Конвертер).

### Параметр `split`

Отвечает за то, какой сплит из датасета использовать, если его не указывать то будет использоваться скрипт `train`.

Помимо этого можно указать и диапазон сэмплов, которые вы хотите использовать при обучении модели, скажем требуется
взять первые 1000 сэмплов из датасета:

```yml
datasets:
  - name: korotkov/glaive-function-calling-v2-ru-parsed
    split: train[:1000]
```

### Параметр `subset`

Некоторые датасеты имеют так называемые сабсеты у каждого из которых имеются свои сплиты, в качестве примера
могу привести датасет [MERA](https://huggingface.co/datasets/MERA-evaluation/MERA) из одноименного бэнчмарка.

```yml
datasets:
  - name: MERA-evaluation/MERA
    subset: chegeka
    split: test[:100]
```

В данном примере мы берём датасет `MERA`, в нём выбриаем сабсет `chegeka`, в нём первые `100` строк из сплита `test`.

### Параметр `max_tokens_count`

Отвечает за то, сколько максимум токенов разрешено в одном сэмпле, если не указано, то используется соответствующий
параметров токенизатора, если он не задан и в токенизаторе, то брать значение по умолчанию из конфигурации.

```yaml
datasets:
  - name: korotkov/glaive-function-calling-v2-ru-parsed
    max_tokens_count: 1024
```

### Параметры `add_global_bos` и `add_global_eos`  

По умолчанию `add_global_bos` и `add_global_eos` имеют значение `true`, отвечают они за то будет ли в момент
предобработки датасета к _каждому_ элементу из датасета добавлен префикс с токенов BOS-токен (Begin of String)
в начале и EOS-токен (End of String) в конце.

Например, у нас имеется `bos=1` и `eos=2`, в момент преобразования текста в последовательность токенов
(при помощи токенизатор) по умолчанию получается массив токенов вида:

```json
[1, 456, 76, 84, 5667, 2]
```

Однако, если `add_global_bos` и `add_global_eos` имеют значение `false`, тогда токенизатор вернёт:

```json
[456, 76, 84, 5667]
```

Пример конфигурации:

```yml
datasets:
  - name: MexIvanov/Vezora-Tested-22k-Python-Alpaca-ru
    converter: impruver.instruction_to_messages
    add_global_bos: false
    add_global_eos: false
```

### Параметр `mapping`

> Указанный параметр может быть использован только в конвертере `impruver.instruction_to_messages` 

Традиционно `instruct` датасеты имеют три колонки в которых хранятся данные:

* `instruction` - инструкция, которую модель должна выполнить;
* `input` - (опционально) некая вспомогательная информация, контекст или пример того, как модель должна ответить; 
* `output` - ожидаемый ответ модели.

Но бывают случаи, когда скажем колонка `instruction` имеет другое название, например `вопрос`, а вместо `output`
используется `выводв` и требуется смапить данные так, чтобы конвертер датасета мог это распарсить.

```yml
datasets:
  - name: zelkame/ru-stackoverflow-py
    converter: impruver.instruction_to_messages
    mapping:
      instruction: вопрос
      output: ответ
```

## Секция `tokenizer`

Данная секция описывает, то какой токенизатор использовать в процессе комбинирования датасета и (до)обучения модели.

```yaml
tokenizer:
  class: transformers.AutoTokenizer
  name: ai-forever/rugpt3large_based_on_gpt2
```

### Параметр `class`

Отвечает за то какой класс необходимо использовать для инициализации токенизатора.

В качестве класса можно указать путь до любого другого подходящего вам класса, например:

```yaml
tokenizer:
  class: transformers.GPT2Tokenizer
  name: openai-community/gpt2
```

Так же можно указать путь до пакета содержащего класс и название класса на файловой системе, важно только, чтобы его
сигнатура была совместима с форматом классов представленных в пакете `transformers`. 

```yaml
tokenizer:
  class: ru-gpts.src.xl_wrapper.GPT2Tokenizer
  name: ai-forever/rugpt3xl
```

### Параметр `name`

Позволяет указать токенизатор из какой модели необходимо использовать в процессе обучения, можно указать
как `repo_id` на HuggingFace, так и путь до директории (абсолютный или относительный) в которой будут находиться
конфигурация токенизатора, его словарь и список специальных токенов.

```yaml
tokenizer:
  class: transformers.GPT2Tokenizer
  name: ./models/gpt2
```

## Секция `model`

Данная секция описывает, то какую модель необходим использовать в процессе (до)обучения модели, как её загрузить,
в какую битность квантовать и так далее.

```yml
model:
  class: transformers.AutoModelForCausalLM
  name: ai-forever/rugpt3small_based_on_gpt2
  dtype: bf16
```

### Параметр `class`

Отвечает за то какой класс необходимо использовать для инициализации трансформерной модели, это может быть класс
из пакета `transfomers` или какой-то кастомный класс, совместимый с форматом `transformers`.

В качестве класса можно указать путь до любого другого подходящего вам класса, например:

```yaml
model:
  class: transformers.AutoModelForCausalLM
  name: ai-forever/rugpt3small_based_on_gpt2
```

Используя класс `AutoModelForCausalLM` из пакета `transformers` загрузит модель `ai-forever/rugpt3small_based_on_gpt2`.

### Параметр `name`

Позволяет указать модель, которую необходимо использовать в процессе обучения, можно указать
как `repo_id` на HuggingFace, так и путь до директории (абсолютный или относительный) в которой будут находиться
веса и конфигурация модели.
