# Dataset
dataset:
  _component_: torchtune.datasets.alpaca_dataset
seed: null
shuffle: True

# Tokenizer
tokenizer:
  _component_: transformers.AutoTokenizer
  path: ai-forever/rugpt3small_based_on_gpt2

# Model Arguments
model:
  _component_: transformers.AutoModelForCausalLM
  path: ai-forever/rugpt3small_based_on_gpt2

# LoRA adapter training
lora:
  r: 32
  lora_alpha: 16
  lora_dropout: 0.0
  bias: "none"
  target_modules: [ "c_attn", "c_proj", "c_fc" ]
  modules_to_save: [ "lm_head" ]

# Model quantization settings
quantization:
  load_in_4bit: True

# Reduced precision
dtype: fp16

# Training env
device: cuda

